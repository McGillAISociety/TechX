{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 8 - Convolutional Neural Networks\n",
    "\n",
    "Congratulations! You have made it to the last assignment of the TechX Machine Learning bootcamp. In the following assignment, you will explore with convolutional neural networks (CNNs) by training a classifier to recognize the difference between images of cats and dogs. The training time of this assignment will take longer than previous ones, so it reccommended to run this on a GPU.\n",
    "\n",
    "Start by downloading and unzipping the dataset to your local environment: [https://techx.blob.core.windows.net/cats-and-dogs/dataset.zip](https://techx.blob.core.windows.net/cats-and-dogs/dataset.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "As usual, let's start by importing the necessary libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import activations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods\n",
    "Below are some helper methods that have been created for usage later in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed = []\n",
    "    for point in points:\n",
    "        if smoothed:\n",
    "            previous = smoothed[-1]\n",
    "            smoothed.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed.append(point)\n",
    "    return smoothed\n",
    "\n",
    "def plot_compare(history, steps=-1):\n",
    "    if steps < 0:\n",
    "        steps = len(history.history['acc'])\n",
    "    acc = smooth_curve(history.history['acc'][:steps])\n",
    "    val_acc = smooth_curve(history.history['val_acc'][:steps])\n",
    "    loss = smooth_curve(history.history['loss'][:steps])\n",
    "    val_loss = smooth_curve(history.history['val_loss'][:steps])\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(loss, c='#0c7cba', label='Train Loss')\n",
    "    plt.plot(val_loss, c='#0f9d58', label='Val Loss')\n",
    "    plt.xticks(range(0, len(loss), 5))\n",
    "    plt.xlim(0, len(loss))\n",
    "    plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(acc, c='#0c7cba', label='Train Acc')\n",
    "    plt.plot(val_acc, c='#0f9d58', label='Val Acc')\n",
    "    plt.xticks(range(0, len(acc), 5))\n",
    "    plt.xlim(0, len(acc))\n",
    "    plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    " \n",
    "def save_history(history, fn):\n",
    "    with open(fn, 'wb') as fw:\n",
    "        pickle.dump(history.history, fw, protocol=2)\n",
    "\n",
    "def load_history(fn):\n",
    "    class Temp():\n",
    "        pass\n",
    "    history = Temp()\n",
    "    with open(fn, 'rb') as fr:\n",
    "        history.history = pickle.load(fr)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Load Data and Prepare Data\n",
    "\n",
    "When it comes to CNNs, we are usually working with data that takes up a large amount of space which means we will need to load the data in batches. You'll also notice that the dataset only has 1500 images for each class, which is not nearly enough data to train an accurate classifier using a deep neural network approach. As a result, we will need to augment our data as well - perform linear transformations on the existing data in order to create additional new data.\n",
    "\n",
    "Luckily, there is [built in functionality in keras](https://keras.io/preprocessing/image/) to help us load our data in batches while augmenting it in real-time. Let's start by using this library to load and prepare our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by setting the root path of your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========== YOUR CODE HERE ========= ##\n",
    "base_dir = '<ROOT DIRECTORY OF YOUR DATASET>'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create instances of the ImageDataGenerator object for the train and test data with the following parameters:\n",
    "1) Train data:\n",
    "- Rescale: 1./255\n",
    "- Rotation Range: 40\n",
    "- Width Shift Range: 0.2\n",
    "- Height Shift Range: 0.2\n",
    "- Shear Range: 0.2\n",
    "- Zoom Range: 0.2\n",
    "- Horizontal Flip: True\n",
    "\n",
    "2) Test data:\n",
    "- Rescale: 1./255\n",
    "\n",
    "#### Use the online documentation for support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========== YOUR CODE HERE (UNCOMMENT AND FILL IN CODE BELOW) ========= ##\n",
    "\n",
    "# train_datagen = ImageDataGenerator(<ADD PROPER PARAMETERS>)\n",
    "# test_datagen = ImageDataGenerator(<ADD PROPER PARAMETERS>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the directory, target size (150,150), batch size (32), and class mode (binary) on the data generator instances using the .flow_from_directory method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========== YOUR CODE HERE (UNCOMMENT AND FILL IN CODE BELOW) ========= ##\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(<ADD PROPER PARAMETERS>)\n",
    "# validation_generator = test_datagen.flow_from_directory(<ADD PROPER PARAMETERS>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Build and Train Custom Model\n",
    "Now that our data is ready, it is time to start training our model. This section will first go over an example of how to build a custom CNN architecture and train our data on this model. Then you will be given the outline for another custom architecture which you will have to build and train by yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the first custom model, we will create and compile a sequential model with the following architecture\n",
    "- Convolution layer with 32 filters, 3x3 kernel, relu activation, and padding\n",
    "- Max pooling layer with a size of 2x2\n",
    "- Flattening layer\n",
    "- Densely connected output layer with dimension of 1 and sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the model defined above\n",
    "model_custom1 = Sequential()\n",
    "model_custom1.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1', \n",
    "                 input_shape=(150, 150, 3)))\n",
    "model_custom1.add(MaxPooling2D((2, 2), name='maxpool_1'))\n",
    "model_custom1.add(Flatten())\n",
    "model_custom1.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "# compile the model\n",
    "model_custom1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can print a summary of the architecture as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_custom1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now train and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train model for 50 epochs, with 100 steps per epoch, and 50 validation steps\n",
    "history_custom1 = model_custom1.fit_generator(train_generator, steps_per_epoch=100, epochs=50, \n",
    "                                      validation_data=validation_generator, validation_steps=50, verbose=1)\n",
    "\n",
    "# save the model and its history\n",
    "model_custom1.save('model-custom1.h5')\n",
    "save_history(history_custom1, 'history_custom1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "history_custom1 = load_history('history_custom1.bin')\n",
    "plot_compare(history_custom1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's your turn! Build a new custom model with the following architecture: \n",
    "- Convolution layer with 32 filters, 3x3 kernel, relu activation, and padding\n",
    "- Max pooling layer with a size of 2x2\n",
    "- Convolution layer with 64 filters, 3x3 kernel, relu activation, and padding\n",
    "- Max pooling layer with a size of 2x2\n",
    "- Convolution layer with 128 filters, 3x3 kernel, relu activation, and padding\n",
    "- Max pooling layer with a size of 2x2\n",
    "- Convolution layer with 128 filters, 3x3 kernel, relu activation, and padding\n",
    "- Max pooling layer with a size of 2x2\n",
    "- Flattening layer\n",
    "- Dropout layer with 0.5 dropout rate\n",
    "- Densely connected layer with dimension of 512 and relu activation function\n",
    "- Densely connected layer with dimension of 256 and relu activation function\n",
    "- Densely connected output layer with dimension of 1 and sigmoid activation function\n",
    "\n",
    "#### Follow the same method as above and plot the results afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ========== YOUR CODE HERE ========= ##\n",
    "\n",
    "# create the model defined above\n",
    "\n",
    "# compile the model\n",
    "\n",
    "# train model for 50 epochs, with 100 steps per epoch, and 50 validation steps\n",
    "\n",
    "# save the model and its history\n",
    "\n",
    "# plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which of the two custom models performed better? What do you think contributed to the better performance? How do you think you could improve the model even more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========== YOUR ANSWER HERE ========= ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Explore On Your Own!\n",
    "\n",
    "#### Use your proposed methods in the previous question to try and improve the performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ========== YOUR CODE HERE ========= ##\n",
    "\n",
    "# Train your own custom model here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
